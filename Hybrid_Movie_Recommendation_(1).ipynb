{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg49hm9hPsKh",
        "outputId": "ce2c5e36-ab66-4db0-985c-0bf397f71543"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiQZStEdz8GS",
        "outputId": "8659b152-2bae-4d46-8ba4-ea8b923090ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357282 sha256=11b4cf745de7aee2a58d7901d47c2cccc1f0c4b21d72a3338279f5dac7f0798c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETGiGxH4zpGz",
        "outputId": "06f7a83a-860b-4319-f884-64262cf30524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7dd29747f820>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load and sample data\n",
        "movies = pd.read_csv('/content/drive/MyDrive/mvrec/movies.csv')\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/mvrec/ratings.csv')\n",
        "\n",
        "# TF-IDF Vectorizer for genres with sparse output\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "movies['genres'] = movies['genres'].fillna('')\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Prepare the data for Surprise\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Train-test split\n",
        "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Use SVD algorithm with reduced factors to save memory\n",
        "svd = SVD(n_factors=50)  # Reduce the number of factors for memory efficiency\n",
        "svd.fit(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Assuming your titles are in the format \"Movie Title (Year)\"\n",
        "def extract_year(title):\n",
        "    match = re.search(r'\\((\\d{4})\\)', title)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "# Apply the extraction function\n",
        "movies['year'] = movies['title'].apply(extract_year)\n",
        "\n",
        "# Check if the 'year' column was successfully added\n",
        "print(movies[['title', 'year']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OfC0RxEX3VP",
        "outputId": "530cdd59-1f6e-4611-9648-80b02b1cd65a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                title    year\n",
            "0                    Toy Story (1995)  1995.0\n",
            "1                      Jumanji (1995)  1995.0\n",
            "2             Grumpier Old Men (1995)  1995.0\n",
            "3            Waiting to Exhale (1995)  1995.0\n",
            "4  Father of the Bride Part II (1995)  1995.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommendations(user_id, movie_id, movies_df, svd_model, cosine_sim_matrix):\n",
        "    # Check if the movie_id exists in the dataset\n",
        "    if movie_id not in movies_df['movieId'].values:\n",
        "        return f\"Error: Movie ID '{movie_id}' not found in the dataset.\"\n",
        "\n",
        "    # Find the index of the movie in the DataFrame\n",
        "    idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Get the movie IDs for the similar movies\n",
        "    similar_movie_ids = movies_df.iloc[movie_indices]['movieId']\n",
        "\n",
        "    # Collaborative filtering scores\n",
        "    cf_scores = [svd_model.predict(user_id, mid).est for mid in similar_movie_ids]\n",
        "\n",
        "    # Combine the results\n",
        "    hybrid_scores = [(movies_df['title'].iloc[i], cf_scores[j], sim_scores[j][1])\n",
        "                     for j, i in enumerate(movie_indices)]\n",
        "    hybrid_scores = sorted(hybrid_scores, key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "    return hybrid_scores\n",
        "\n",
        "# Example usage:\n",
        "user_id = 1\n",
        "movie_id = 5  # Use the movie ID here\n",
        "recommendations = hybrid_recommendations(user_id, movie_id, movies, svd, cosine_sim)\n",
        "\n",
        "if isinstance(recommendations, str):  # Check if an error message was returned\n",
        "    print(recommendations)\n",
        "else:\n",
        "    for title, cf_score, sim_score in recommendations:\n",
        "        print(f\"Movie: {title}, CF Score: {cf_score:.2f}, Similarity: {sim_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "zX6O-bKSz2-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65f7549-1a2a-44a9-839c-8d474f877bb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie: Friday (1995), CF Score: 4.68, Similarity: 1.00\n",
            "Movie: Flirting With Disaster (1996), CF Score: 4.43, Similarity: 1.00\n",
            "Movie: Four Rooms (1995), CF Score: 4.42, Similarity: 1.00\n",
            "Movie: Happy Gilmore (1996), CF Score: 4.27, Similarity: 1.00\n",
            "Movie: Steal Big, Steal Little (1995), CF Score: 4.27, Similarity: 1.00\n",
            "Movie: Black Sheep (1996), CF Score: 4.22, Similarity: 1.00\n",
            "Movie: Down Periscope (1996), CF Score: 3.98, Similarity: 1.00\n",
            "Movie: Mr. Wrong (1996), CF Score: 3.97, Similarity: 1.00\n",
            "Movie: Ace Ventura: When Nature Calls (1995), CF Score: 3.52, Similarity: 1.00\n",
            "Movie: Bio-Dome (1996), CF Score: 3.42, Similarity: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_year_weight(year, min_year, max_year):\n",
        "    # Normalize the year between 0 and 1\n",
        "    normalized_year = (year - min_year) / (max_year - min_year)\n",
        "\n",
        "    # Apply a non-linear transformation for dynamic weighting\n",
        "    # For example, squaring the normalized year gives more weight to recent movies\n",
        "    year_weight = normalized_year ** 2\n",
        "\n",
        "    return year_weight\n",
        "\n",
        "def hybrid_recommendations(user_id, movie_id, movies_df, svd_model, cosine_sim_matrix):\n",
        "    # Check if the movie_id exists in the dataset\n",
        "    if movie_id not in movies_df['movieId'].values:\n",
        "        return f\"Error: Movie ID '{movie_id}' not found in the dataset.\"\n",
        "\n",
        "    # Find the index of the movie in the DataFrame\n",
        "    idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]  # Top 10 similar movies\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Get the movie IDs and years for the similar movies\n",
        "    similar_movies = movies_df.iloc[movie_indices]\n",
        "    similar_movie_ids = similar_movies['movieId']\n",
        "    similar_movie_years = similar_movies['year']\n",
        "\n",
        "    # Collaborative filtering scores\n",
        "    cf_scores = [svd_model.predict(user_id, mid).est for mid in similar_movie_ids]\n",
        "\n",
        "    # Define the range of years in the dataset\n",
        "    min_year = movies_df['year'].min()\n",
        "    max_year = movies_df['year'].max()\n",
        "\n",
        "    # Combine the scores with dynamic year weighting\n",
        "    hybrid_scores = []\n",
        "    for j, i in enumerate(movie_indices):\n",
        "        # Calculate the year weight\n",
        "        year_weight = calculate_year_weight(similar_movie_years.iloc[j], min_year, max_year)\n",
        "\n",
        "        # Final score = (CF Score * 0.5) + (Similarity Score * 0.4) + (Year Weight * 0.1)\n",
        "        final_score = (cf_scores[j] * 0.5) + (sim_scores[j][1] * 0.4) + (year_weight * 0.1)\n",
        "\n",
        "        hybrid_scores.append((movies_df['title'].iloc[i], final_score, cf_scores[j], sim_scores[j][1], year_weight))\n",
        "\n",
        "    # Sort by final hybrid score\n",
        "    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return hybrid_scores\n",
        "\n",
        "# Example usage:\n",
        "user_id = 1\n",
        "movie_id = 15  # Use the movie ID here\n",
        "recommendations = hybrid_recommendations(user_id, movie_id, movies, svd, cosine_sim)\n",
        "\n",
        "if isinstance(recommendations, str):  # Check if an error message was returned\n",
        "    print(recommendations)\n",
        "else:\n",
        "    for title, final_score, cf_score, sim_score, year_weight in recommendations:\n",
        "        print(f\"Movie: {title}, Final Score: {final_score:.2f}, CF Score: {cf_score:.2f}, Similarity: {sim_score:.2f}, Year Weight: {year_weight:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wElBLspUXXu3",
        "outputId": "073d6b00-5498-4236-9908-731d0d17a6c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie: Adventures of Robin Hood, The (1938), Final Score: 2.72, CF Score: 4.62, Similarity: 1.00, Year Weight: 0.10\n",
            "Movie: Host, The (2013), Final Score: 2.62, CF Score: 4.26, Similarity: 1.00, Year Weight: 0.92\n",
            "Movie: Captain Blood (1935), Final Score: 2.60, CF Score: 4.38, Similarity: 1.00, Year Weight: 0.08\n",
            "Movie: Eight Below (2006), Final Score: 2.57, CF Score: 4.23, Similarity: 0.94, Year Weight: 0.80\n",
            "Movie: Helen of Troy (2003), Final Score: 2.55, CF Score: 4.21, Similarity: 0.94, Year Weight: 0.76\n",
            "Movie: King Solomon's Mines (1950), Final Score: 2.55, CF Score: 4.26, Similarity: 1.00, Year Weight: 0.17\n",
            "Movie: Three Musketeers, The (1948), Final Score: 2.51, CF Score: 4.24, Similarity: 0.94, Year Weight: 0.16\n",
            "Movie: Three Musketeers, The (1993), Final Score: 2.40, CF Score: 3.94, Similarity: 0.93, Year Weight: 0.62\n",
            "Movie: Musketeer, The (2001), Final Score: 2.39, CF Score: 3.88, Similarity: 0.94, Year Weight: 0.73\n",
            "Movie: Jewel of the Nile, The (1985), Final Score: 2.30, CF Score: 3.75, Similarity: 0.93, Year Weight: 0.51\n"
          ]
        }
      ]
    }
  ]
}